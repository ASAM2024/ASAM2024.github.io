<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="ASAM2024">
  <meta name="keywords" content="ASAM2024">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- <meta property="og:image" content="./static/img/logo.png"/> -->
  <!-- <link rel="image_src" href="./static/img/logo.png"> -->
  <!-- <link rel="icon"
        type="image/x-icon"
        href="./static/img/logo.png"/> -->

  <title>
    ASAM (CVPR2024): Boosting Segment Anything Model with Adversarial Tuning
  </title>

  <script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-EDF010G6PN');


  </script>


  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
  <script type="text/javascript" src="https://code.jquery.com/jquery-1.11.0.min.js"></script>
  <script type="text/javascript" src="https://code.jquery.com/jquery-migrate-1.2.1.min.js"></script>
  <script src="https://unpkg.com/interactjs/dist/interact.min.js"></script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" type="text/css" href="./static/slick/slick.css"/>
  <link rel="stylesheet" type="text/css" href="./static/slick/slick-theme.css"/>

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <link rel="stylesheet" href="./static/css/gradient_color.css">
  
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
    </div>

  </div>
</nav>

<section class="hero">
  <div class="hero-body">
    <div class="container">
      <!-- <div class="columns is-centered">
        <div class="column is-8 has-text-centered">
          <img src="static/figs/diffusion.png" height="100%" alt="logo"/>
        </div>
      </div> -->
      <div class="container has-text-centered">
        <h1 class="title is-1 publication-title">
          <h1 class="gradient-text">ASAM</h1> <font size="6">Boosting Segment Anything Model with Adversarial Tuning </font> 
        </h1>
        <br> <font size="5">CVPR 2024</font>
        <div class="is-size-5 publication-authors">
          <div class="author-block">
            <a href="https://scholar.google.com/citations?user=NVzQ87sAAAAJ&hl=zh-CN">Bo Li</a>,
          </div>
          <div class="author-block">
            <a href="https://scholar.google.com.hk/citations?user=bJmhMKEAAAAJ&hl=zh-CN">HaoKe Xiao</a>,
          </div>
          <div class="author-block">
            <a href="https://scholar.google.com/citations?user=BSTLuZcAAAAJ&hl=zh-CN">Lv Tang</a>
          </div>
        <div class="is-size-5 publication-authors">
          <span class="author-block">vivo Mobile Communication Co., Ltd</span>
        </div>
        <!-- <div class="is-size-6 publication-authors">
          <span class="author-block"><sup>*</sup>Most work done during internship at Adobe Research</span>
        </div> -->

        <div class="column has-text-centered">
          <div class="publication-links">
            <!-- PDF Link. -->
            <!-- <span class="link-block">
                <a href="https://arxiv.org/pdf/2106.13228.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
            <span class="link-block">
                <!-- <a href="SegGen_arxiv.pdf" -->
                <a href="https://arxiv.org/abs/2403.15389"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
            </span>
            <span class="link-block">
              <a href="https://github.com/luckybird1994/ASAM"
                 class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                    <i class="fab fa-github"></i>
                </span>
                <span>Github</span>
                </a>
            </span>
            <!-- Dataset Link. -->
            <!-- <span class="link-block">
              <a href="https://github.com/google/hypernerf/releases/tag/v0.1"
                 class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                    <i class="far fa-images"></i>
                </span>
                <span>Data</span>
                </a>
              </span> -->
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <!-- <video id="teaser" autoplay controls muted loop playsinline height="100%">
        <source src="./static/images/teaser.mp4"
                type="video/mp4">
      </video> -->
      <div class="columns is-centered">
        <div class="column is-8 has-text-centered">
          <img src="images/spider.png" height="100%" alt="logo"/>
        </div>
      </div>
      <h2 class="subtitle has-text">
        <font color="#9e2e23"><b><i>ASAM</i></b></font> just boosts the performance of SAM without architectural modifications. ASAM is also resource friendly, since it only needs 8 A6000 GPUs without necessitating additional data (1% SA-1B data).  </h2>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified" style="font-size: 18px;">
          <p>
            In the evolving landscape of computer vision, foundation models have emerged as pivotal tools, exhibiting exceptional adaptability to a myriad of tasks. Among these, the Segment Anything Model (SAM) by Meta AI has distinguished itself in image segmentation. However, SAM, like its counterparts, encounters limitations in specific niche applications, prompting a quest for enhancement strategies that do not compromise its inherent capabilities. This paper introduces ASAM, a novel methodology that amplifies SAM's performance through adversarial tuning. We harness the potential of natural adversarial examples, inspired by their successful implementation in natural language processing. By utilizing a stable diffusion model, we augment a subset (1\%) of the SA-1B dataset, generating adversarial instances that are more representative of natural variations rather than conventional imperceptible perturbations. Our approach maintains the photorealism of adversarial examples and ensures alignment with original mask annotations, thereby preserving the integrity of the segmentation task. The fine-tuned ASAM demonstrates significant improvements across a diverse range of segmentation tasks without necessitating additional data or architectural modifications. The results of our extensive evaluations confirm that ASAM establishes new benchmarks in segmentation tasks, thereby contributing to the advancement of foundational models in computer vision.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-2">Video</h2>
        <div class="publication-video">
          <iframe width="640" height="480" src="https://www.youtube.com/embed/qzgdE_ghkaI"
                  title="YouTube video player" frameborder="0"
                  allow="accelerometer; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                  allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>

  <div class="columns is-centered has-text-centered">
    <h2 class="title is-3 centered">Framework</h2>
  </div>

<section class="hero teaser">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <img src="images/framework.png" height="100%" ></img>
      <h2 class="subtitle has-text">
      <b>ASAM mainly contains three step.</b> The first step is <b>Adversarial Latent Optimization.</b> The second step is <b>Controllable Adversarial Samples Generation.</b> The third step is <b>Fine-tuning SAM</b> with adversarial samples.
      </h2>
      </div>
  </div>
</section>

<div class="columns is-centered has-text-centered">
  <h2 class="title is-3 centered">Experiments: Stronger SAM</h2>
</div>

<section class="hero teaser">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <!-- <video id="teaser" autoplay controls muted loop playsinline height="100%">
        <source src="./static/images/teaser.mp4"
                type="video/mp4">
      </video> -->
      <img src="images/ASAM_performance.png" height="100%" ></img>
      <!-- <h2 class="subtitle has-text-centered"> -->
      <h2 class="subtitle has-text">
        <b><i>Stronger SAM.</i></b> Compared with PGD-Tuning SAM, DAT-Tuning SAM, DatasetDM-Tuning SAM. ASAM clearly outperforms other tuning methods and achieves performance improvements compared with original SAM across all 14 test datasets.
      </h2>
    </div>
  </div>
</section>

<section class="hero is-dark is-small">
  <div class="hero-body">
    <div class="container has-text-centered">

      <div id="results-carousel" class="carousel results-carousel">

        <div>
          <div class="results-item">
            <image src="images/vis.png"  style="padding-right: 200px; padding-left: 200px;"></image>
            <figcaption>Qualitative comparison of the proposed ASAM and other methods. Yellow boxes represent the box prompts.
            </figcaption>
          </div>
        </div>

        <div>
          <div class="results-item">
            <image src="images/hugeface.jpg" style="padding-right: 200px; padding-left: 200px;"></image>
            <figcaption>The demo we provided in HugeFace.
            </figcaption>
          </div>
        </div>

    </div>

      <div class="columns is-centered has-text-centered">
        <div class="column is-three-quarters is-size-5">
          <p>
            From the qualitative comparison, our proposed ASAM can improve the performance of SAM.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<hr/>

<div class="columns is-centered has-text-centered">
  <h2 class="title is-3 centered">Experiments: Stronger EfficientSAM</h2>
</div>

<section class="hero teaser">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <!-- <video id="teaser" autoplay controls muted loop playsinline height="100%">
        <source src="./static/images/teaser.mp4"
                type="video/mp4">
      </video> -->
      <img src="images/AESAM.png" height="100%" style="padding-right: 200px; padding-left: 200px;"></img>
      <!-- <h2 class="subtitle has-text-centered"> -->
      <h2 class="subtitle has-text">
        <b><i>Stronger EfficientSAM.</i></b> AESAM achieves performance improvements compared with EfficientSAM (ESAM,CVPR2024) across 5 different datasets. <a href="https://arxiv.org/abs/2312.00863">ESAM</a> is the latest work proposed by Meta, which is accepted with full marks at CVPR2024.
      </h2>
    </div>
  </div>
</section>
      
<section class="hero teaser">
  <div class="hero-body">
    <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-3 centered">Experiments: Stronger HQSAM</h2>
      </div>
        <img src="images/HQSAM.png"/>
      <h2 class="subtitle has-text">
         <b><i>Stronger HQSAM.</i></b> HQ-ASAM can achieve performance improvements compared with HQSAM (NeurIPS2023) across 4 different datasets. <a href="https://github.com/SysCV/sam-hq">HQSAM</a> is the work proposed by ETH Zurich&HKUST, which achieves about 3.4k Github stars.
      </h2>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="hero-body">
    <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-3 centered">Experiments: Stronger SAM-Adapter</h2>
      </div>
        <img src="images/SAM-Adapter.png"/>
      <h2 class="subtitle has-text">
         <b><i>Stronger SAM-Adapter.</i></b> ASAM-Adapter achieves performance improvements compared with SAM-adapter (ICCV2023 Workshop) across 2 different datasets.
      </h2>
    </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container content is-max-desktop">
    <h2 class="title">BibTeX</h2>
    <pre><code>@InProceedings{asam2024,
  title={ASAM: Boosting Segment Anything Model with Adversarial Tuning},
  author={Bo Li, Haoke Xiao, Lv Tang},
  booktitle={CVPR},
  year={2024}
}</code></pre>
  </div>
</section>


<section class="section" id="acknowledgements">
  <div class="container content is-max-desktop">
  The website template was adapted from
    <a href="https://seggenerator.github.io/">SegGen</a>.
  </div>
</section>



<script type="text/javascript" src="./static/slick/slick.min.js"></script>
</body>
</html>
